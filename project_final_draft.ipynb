{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project final draft.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1Ag7mpCARnrxHz_kVEWlj54kaYx7rxDCq",
      "authorship_tag": "ABX9TyNND5AkH1WKts6MrxUXUtdx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubhampoonia/shubhampoonia.github.io/blob/master/project_final_draft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbYYpFCY_1i4",
        "colab_type": "text"
      },
      "source": [
        "# **Importing necessary packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYQhszProO9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "from PIL import Image, ImageOps\n",
        "from keras.layers import Dense,GlobalAveragePooling2D\n",
        "from keras.applications import MobileNet\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M0SsXkDAehM",
        "colab_type": "text"
      },
      "source": [
        "# **Importing Pretained Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpu-ryBRocZK",
        "colab_type": "code",
        "outputId": "12a31685-fcb0-474a-fd98-90c723080eda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "base_model=MobileNet(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
        "\n",
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
        "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
        "x=Dense(512,activation='relu')(x) #dense layer 3\n",
        "preds=Dense(2,activation='softmax')(x) #final layer with softmax activation"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  warnings.warn('`input_shape` is undefined or non-square, '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDk-E-THopfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Model(inputs=base_model.input,outputs=preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76jkPN7XowV0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model.layers[:20]: #freezing top 20 layers\n",
        "    layer.trainable=False\n",
        "for layer in model.layers[20:]:  \n",
        "    layer.trainable=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMd8V7phpUVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_J2nkzU_0PB",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing data using keras ImageDataGenerator function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThSR91aMo3IZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input) #included in our dependencies\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2JY6z3FpbEM",
        "colab_type": "code",
        "outputId": "38101814-a693-456f-a4db-ee22d23663ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_generator=train_datagen.flow_from_directory('/content/drive/My Drive/data/train/', # this is where you specify the path to the main data folder\n",
        "                                                 target_size=(224,224),\n",
        "                                                 color_mode='rgb',\n",
        "                                                 \n",
        "                                                 class_mode='categorical',\n",
        "                                                 )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 72 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrIvSIDEBOl9",
        "colab_type": "text"
      },
      "source": [
        "# Compiling model \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acdIxWowpgpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "# Adam optimizer\n",
        "# loss function will be categorical cross entropy\n",
        "# evaluation metric will be accuracy\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmIAf-eQBkW4",
        "colab_type": "text"
      },
      "source": [
        "# Training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZDyR1atpqYV",
        "colab_type": "code",
        "outputId": "724e4c17-3449-4882-ef2f-b5f2b59c6bd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "step_size_train=train_generator.n//train_generator.batch_size\n",
        "model.fit_generator(generator=train_generator,\n",
        "                   steps_per_epoch=step_size_train,\n",
        "                   epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 14s 7s/step - loss: 4.2746 - accuracy: 0.4375\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 3s 1s/step - loss: 1.4242 - accuracy: 0.6875\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 10s 5s/step - loss: 1.7692 - accuracy: 0.3594\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 9s 5s/step - loss: 0.8067 - accuracy: 0.5938\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.8040 - accuracy: 0.6250\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 10s 5s/step - loss: 0.6867 - accuracy: 0.5781\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 9s 5s/step - loss: 0.6439 - accuracy: 0.6719\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 6s 3s/step - loss: 0.5688 - accuracy: 0.7750\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 6s 3s/step - loss: 0.5273 - accuracy: 0.6500\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 6s 3s/step - loss: 0.3705 - accuracy: 0.9000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fed2bb01c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkvzdXIpBys_",
        "colab_type": "text"
      },
      "source": [
        "# **Pre-processing data which is to be predicted**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwXCZJHiwc58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
        "\n",
        "# Replace this with the path to your image\n",
        "image = Image.open('/content/drive/My Drive/data/validation/benign/mdb312.jpg')\n",
        "\n",
        "#resize the image to a 224x224:\n",
        "#resizing the image to be at least 224x224 and then cropping from the center\n",
        "size = (224, 224)\n",
        "image = ImageOps.fit(image, size, Image.ANTIALIAS)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaDV1N3Jw9Bx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image=image.convert('RGB')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIwj4RQvw-CL",
        "colab_type": "code",
        "outputId": "ec845ad5-fcb5-44cf-ca56-ebac8bc615ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "image.size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 224)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnU73rJkxGTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_array = np.asarray(image)\n",
        "normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oemkZIMAxHZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[0] = normalized_image_array\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVtgz9nWCG9S",
        "colab_type": "text"
      },
      "source": [
        "# Prediction of the model\n",
        "\n",
        "1.  **negative** \n",
        "2.  **positive**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvHtpiXmxMm7",
        "colab_type": "code",
        "outputId": "41d00b00-b2e8-491f-e2bc-720cf1132997",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# run the inference\n",
        "prediction = model.predict(data)\n",
        "\n",
        "print(prediction)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.67515326 0.32484674]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}